{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import spacy\n",
    "from torchtext import data\n",
    "import src.shared.types as types\n",
    "from typing import List, Tuple, Dict, Union, Callable\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    \"\"\"A class to get the information from the batches.\"\"\"\n",
    "\n",
    "    def __init__(self, dataloader, datafield, labelfield):\n",
    "        self.data, self.df, self.lf = dataloader, datafield, labelfield\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __iter__(self):\n",
    "        ipdb.set_trace()\n",
    "        for batch in self.data:\n",
    "            X = getattr(batch, self.df)\n",
    "            y = getattr(batch, self.lf)\n",
    "            yield (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.TabularDataset):\n",
    "\n",
    "    def __init__(self, data_dir: str, splits: Dict[str, str], ftype: str,\n",
    "                 fields: List[Tuple[types.FieldType, ...]] = None, cleaners: List[str] = None,\n",
    "                 batch_sizes: Tuple[int, ...] = (32), shuffle: bool = True, sep: str = 'tab', skip_header: bool = True,\n",
    "                 repeat_in_batches = False, device: str = 'cpu'):\n",
    "        \"\"\"Initialise data class.\n",
    "        :param data_dir (str): Directory containing dataset.\n",
    "        :param fields (Dict[str, str]): The data fields in the file.\n",
    "        :param cleaners List[str]: Cleaning operations to be taken.\n",
    "        :param splits (str): Dictionary containing filenames type of data.\n",
    "        :param ftype: File type of the data file.\n",
    "        :param batch_sizes (Tuple[int]): Tuple of batch size for each dataset.\n",
    "        :param shuffle (bool, default: True): Shuffle the data between each epoch.\n",
    "        :param sep (str): Seperator (if csv/tsv file).\n",
    "        :param repeat_in_batches (bool, default: False): Repeat data within batches\n",
    "        :param device (str, default: 'cpu'): Device to process on\n",
    "        \"\"\"\n",
    "        self.tagger = spacy.load('en', disable = ['ner'])\n",
    "        num_files = len(splits.keys())  # Get the number of datasets.\n",
    "\n",
    "        self.load_params = {'path': data_dir,\n",
    "                            'format': ftype,\n",
    "                            'fields': fields,\n",
    "                            'skip_header': skip_header,\n",
    "                            'num_files': num_files}\n",
    "        self.load_params.update(splits)\n",
    "        self.dfields = fields\n",
    "        self.batch_sizes = batch_sizes\n",
    "        self.repeat = repeat_in_batches\n",
    "        self.cleaners = cleaners\n",
    "        self.device = device\n",
    "\n",
    "    @property\n",
    "    def fields(self):\n",
    "        return self.dfields\n",
    "\n",
    "    @fields.setter\n",
    "    def fields(self, fields):\n",
    "        self.dfields = fields\n",
    "        self.load_params.update({'fields': fields})\n",
    "\n",
    "    @property\n",
    "    def data_params(self):\n",
    "        return self.load_params\n",
    "\n",
    "    @data_params.setter\n",
    "    def data_params(self, params):\n",
    "        self.load_params.update(params)\n",
    "\n",
    "    def load_data(self) -> Tuple[types.DataType, ...]:\n",
    "        \"\"\"Load the dataset and return the data.\n",
    "        :return data: Return loaded data.\n",
    "        \"\"\"\n",
    "        if self.load_params['num_files'] == 1:\n",
    "            train = self._data(**self.load_params)\n",
    "            self.data = (train, None, None)\n",
    "        elif self.load_params['num_files'] == 2:\n",
    "            train, test = self._data(**self.load_params)\n",
    "            self.data = (train, None, test)\n",
    "        elif self.load_params['num_files'] == 3:\n",
    "            train, dev, test = self._data(**self.load_params)\n",
    "            self.data = (train, dev, test)\n",
    "        return self.data\n",
    "\n",
    "    @classmethod\n",
    "    def _data(cls, path: str, format: str, fields: Union[List[Tuple[types.FieldType, ...]], Dict[str, tuple]],\n",
    "              train: str, validation: str = None, test: str = None, skip_header: bool = True,\n",
    "              num_files: int = 3) -> Tuple[types.DataType, ...]:\n",
    "        \"\"\"Use the loader in torchtext.\n",
    "        :param path (str): Directory the data is stored in.\n",
    "        :param format (str): Format of the data.\n",
    "        :param fields (Union[List[types.FieldType], Dict[str tuple]]): Initialised fields.\n",
    "        :param train (str): Filename of the training data.\n",
    "        :param validation (str, default: None): Filename of the development data.\n",
    "        :param test (str, default: None): Filename of the test data.\n",
    "        :param skip_header (bool, default: True): Skip first line.\n",
    "        :param num_files (int, default: 3): Number of files/datasets to load.\n",
    "        :return data: Return loaded data.\n",
    "        \"\"\"\n",
    "        splitted = data.TabularDataset.splits(path = path, format = format, fields = fields, train = train,\n",
    "                                              validation = validation, test = test, skip_header = skip_header)\n",
    "        return splitted\n",
    "\n",
    "    def clean_document(self, text: types.DocType, processes: List[str] = None):\n",
    "        \"\"\"Data cleaning method.\n",
    "        :param text (types.DocType): The document to be cleaned.\n",
    "        :param processes (List[str]): The cleaning processes to be undertaken.\n",
    "        :return cleaned: Return the cleaned text.\n",
    "        \"\"\"\n",
    "        cleaned = str(text)\n",
    "        if 'lower' in self.cleaners or 'lower' in processes:\n",
    "            cleaned = cleaned.lower()\n",
    "        if 'url' in self.cleaners or 'url' in processes:\n",
    "            cleaned = re.sub(r'https?:/\\/\\S+', '<URL>', cleaned)\n",
    "        if 'hashtag' in self.cleaners or 'hashtag' in processes:\n",
    "            cleaned = re.sub(r'#[a-zA-Z0-9]*\\b', '<HASHTAG>', cleaned)\n",
    "        if 'username' in self.cleaners or 'username' in processes:\n",
    "            cleaned = re.sub(r'@\\S+', '<USER>', cleaned)\n",
    "\n",
    "        return cleaned\n",
    "\n",
    "    def tokenize(self, document: types.DocType, processes: List[str] = None):\n",
    "        \"\"\"Tokenize the document using SpaCy and clean it as it is processed.\n",
    "        :param document: Document to be parsed.\n",
    "        :param processes: The cleaning processes to engage in.\n",
    "        :return toks: Document that has been passed through spacy's tagger.\n",
    "        \"\"\"\n",
    "        if processes:\n",
    "            toks = [tok.text for tok in self.tagger(self.clean_document(document, processes = processes))]\n",
    "        else:\n",
    "            toks = [tok.text for tok in self.tagger(self.clean_document(document))]\n",
    "        return toks\n",
    "\n",
    "    def generate_batches(self, sort_func: Callable, datasets: Tuple[types.DataType, ...] = None):\n",
    "        \"\"\"Create the minibatching here.\n",
    "        :param train (types.DataType, optional): Provide a processed train dataset.\n",
    "        :param test (types.DataType, optional): Provide a processed test dataset.\n",
    "        :param dev (types.DataType, optional): Provide a processed test dataset.\n",
    "        :return ret: Return the batched data.\n",
    "        \"\"\"\n",
    "        if datasets:\n",
    "            batches = data.BucketIterator.splits(datasets,\n",
    "                                                 self.batch_sizes,\n",
    "                                                 #sort_key = sort_func,\n",
    "                                                 device = self.device,\n",
    "                                                 #sort_within_batch = True, \n",
    "                                                 repeat = self.repeat)\n",
    "        else:\n",
    "            batches = data.BucketIterator.splits(self.data,\n",
    "                                                 self.batch_sizes,\n",
    "                                                 #sort_key = sort_func,\n",
    "                                                 device = self.device,\n",
    "                                                 #sort_within_batch = True, \n",
    "                                                 repeat = self.repeat)\n",
    "        return batches\n",
    "\n",
    "    def tag(self, document: types.DocType):\n",
    "        \"\"\"Tag document using spacy.\n",
    "        :param document: Document to be parsed.\n",
    "        :return doc: Document that has been passed through spacy's tagger.\n",
    "        \"\"\"\n",
    "        doc = self.tagger(self.clean_document(document))\n",
    "        return doc\n",
    "\n",
    "    def get_spacy_annotations(self, document: types.DocType, processes: List[str]) -> Tuple:\n",
    "        \"\"\"Get annotations from SpaCy requested.\n",
    "        :param document: The document to process.\n",
    "        :param processes: The annotation processes to get.\n",
    "        :return res (tuple): Tuple containing annotations requested.\n",
    "        \"\"\"\n",
    "        res = [(tok.text, tok.pos_, tok.dep_, (tok.dep_, tok.head.dep_)) for tok in document]\n",
    "        token, pos, dep, head = zip(*res)\n",
    "\n",
    "        res = [None, None, None, None]\n",
    "\n",
    "        if 'token' in processes:\n",
    "            res[0] = token\n",
    "        if 'pos' in processes:\n",
    "            res[1] = pos\n",
    "        if 'dep' in processes:\n",
    "            res[2] = dep\n",
    "        if 'head' in processes:\n",
    "            res[3] = head\n",
    "        if 'children' in processes:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        return tuple(res)\n",
    "\n",
    "    def set_field_attribute(field: Union[types.FieldType, List[types.FieldType]], attribute: Union[str, List[str]],\n",
    "                            value: Union[types.Any, List[types.Any]]):\n",
    "        \"\"\"Take an initialised field and an attribute.\n",
    "        :param field (types.FieldType): The field to be modified.\n",
    "        :param attribute (str): The attribute to modify.\n",
    "        :param value (types.AllBuiltin): The new value of the attribute.\n",
    "        \"\"\"\n",
    "        if isinstance(field, list):\n",
    "            assert(len(field) == len(attribute))\n",
    "            assert(len(attribute) == len(value))\n",
    "            for f, attr, val in zip(field, attribute, value):\n",
    "                setattr(f, attr, val)\n",
    "        else:\n",
    "            setattr(field, attribute, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.shared.prep import Dataset, BatchGenerator\n",
    "#from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(data_dir = 'data', \n",
    "             fields = None,\n",
    "             splits = {'train': 'cyberbullying_dataset.csv', 'test': 'test.csv', 'validation': 'dev.csv'},\n",
    "             cleaners = ['lower', 'url', 'hashtag', 'username'],\n",
    "             batch_sizes = (32, 32, 32),\n",
    "             ftype = 'csv',\n",
    "             shuffle = True,\n",
    "             sep = ',',\n",
    "             repeat_in_batches = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = data.Field(sequential=True, \n",
    "                        include_lengths=True,\n",
    "                        tokenize = ds.clean_document,\n",
    "                        use_vocab=True)\n",
    "label_field = data.Field(sequential=False, \n",
    "                         use_vocab=True,  # False if already numerical\n",
    "                         pad_token=None, \n",
    "                         unk_token=None)\n",
    "user_field = data.Field(sequential=False,\n",
    "                        use_vocab=True,\n",
    "                        include_lengths=False)\n",
    "fields = [('id', None), \n",
    "          ('bad_word', text_field), \n",
    "          ('question', text_field), \n",
    "          ('question_sentiment_gold', label_field),\n",
    "          ('answer', text_field),\n",
    "          ('answer_sentiment_gold', label_field),\n",
    "          ('username', user_field)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[('id', None), ('bad_word', <torchtext.data.field.Field object at 0x12b8d7190>), ('question', <torchtext.data.field.Field object at 0x12b8d7190>), ('question_sentiment_gold', <torchtext.data.field.Field object at 0x12b8e29d0>), ('answer', <torchtext.data.field.Field object at 0x12b8d7190>), ('answer_sentiment_gold', <torchtext.data.field.Field object at 0x12b8e29d0>), ('username', <torchtext.data.field.Field object at 0x12b8d7150>)]\n"
     ]
    }
   ],
   "source": [
    "print(ds.fields)\n",
    "ds.fields = fields\n",
    "print(ds.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<torchtext.data.dataset.TabularDataset object at 0x12b8e2150>, <torchtext.data.dataset.TabularDataset object at 0x13372ce50>, <torchtext.data.dataset.TabularDataset object at 0x12963cf10>)\n"
     ]
    }
   ],
   "source": [
    "loaded = ds.load_data()\n",
    "print(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(loaded[0])\n",
    "label_field.build_vocab(loaded[0])\n",
    "user_field.build_vocab(loaded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_func(x):\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = ds.generate_batches(lambda x: len(x.question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = BatchGenerator(train, 'question', 'question_sentiment_gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-2-350779be9cd4>\u001b[0m(12)\u001b[0;36m__iter__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     11 \u001b[0;31m        \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 12 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m            \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "ipdb> \n",
      "ipdb> c\n",
      "((tensor([[34, 14, 11,  ...,  7, 14,  5],\n",
      "        [17,  4, 10,  ...,  5,  4, 10],\n",
      "        [ 6, 11,  2,  ..., 25, 11,  3],\n",
      "        ...,\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1],\n",
      "        [ 1,  1,  1,  ...,  1,  1,  1]]), tensor([ 40,  39, 122,  54,  19,  39,  27,  60,  62,  37,  26,  26,  18, 132,\n",
      "          7,  46,  38,  20,  72,  99,  91,  45,  16,  42,  38,  14, 258, 287,\n",
      "         30, 139,  55, 110])), tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_batches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_batches = BatchGenerator(dev, 'question', 'question_sentiment_gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-2-350779be9cd4>\u001b[0m(12)\u001b[0;36m__iter__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     11 \u001b[0;31m        \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 12 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m            \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "TypeError: '<' not supported between instances of 'Example' and 'Example'\n",
      "> \u001b[0;32m<ipython-input-2-350779be9cd4>\u001b[0m(12)\u001b[0;36m__iter__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     11 \u001b[0;31m        \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 12 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m            \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> quit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-31f57a647f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-350779be9cd4>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c_call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_exception\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     and arg[0] is StopIteration and arg[2] is None):\n\u001b[1;32m    173\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Stop at the StopIteration or GeneratorExit exception when the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# has set stopframe in a generator by issuing a return command, or a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(iter(valid_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
